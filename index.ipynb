{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (4.13.3)\n",
      "Requirement already satisfied: pandas in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: selenium in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (4.30.0)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from beautifulsoup4) (4.13.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: trio~=0.17 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from selenium) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: packaging in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: exceptiongroup in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in d:\\menem\\web_scrapping\\.venv\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.1.0 webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4 pandas selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Extract product name\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m product_name \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mh4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproduct-product\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Extract brand name\u001b[39;00m\n\u001b[0;32m     24\u001b[0m brand_name \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh3\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct-brand\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the Myntra product URL\n",
    "URL = \"https://www.myntra.com/shirts/mast+%26+harbour/mast--harbour-men-blue--white-slim-fit-striped-casual-shirt/8717979/buy\"\n",
    "\n",
    "# Headers to mimic a real browser visit\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "}\n",
    "\n",
    "# Request the webpage\n",
    "response = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "# Check if request was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # Extract product name\n",
    "    product_name = soup.find(\"h4\", class_=\"product-product\").text.strip()\n",
    "    \n",
    "    # Extract brand name\n",
    "    brand_name = soup.find(\"h3\", class_=\"product-brand\").text.strip()\n",
    "    \n",
    "    # Extract price\n",
    "    price = soup.find(\"span\", class_=\"pdp-price\").text.strip()\n",
    "    \n",
    "    # Extract discount percentage\n",
    "    discount = soup.find(\"span\", class_=\"pdp-discount\").text.strip() if soup.find(\"span\", class_=\"pdp-discount\") else \"No discount\"\n",
    "    \n",
    "    # Extract image URL\n",
    "    image_tag = soup.find(\"img\", class_=\"image-grid-image\")\n",
    "    image_url = image_tag[\"src\"] if image_tag else \"No image found\"\n",
    "    \n",
    "    # Extract rating\n",
    "    rating_tag = soup.find(\"div\", class_=\"pdp-rating\")\n",
    "    rating = rating_tag.text.strip() if rating_tag else \"No rating\"\n",
    "    \n",
    "    # Print extracted details\n",
    "    print(f\"Product Name: {product_name}\")\n",
    "    print(f\"Brand: {brand_name}\")\n",
    "    print(f\"Price: {price}\")\n",
    "    print(f\"Discount: {discount}\")\n",
    "    print(f\"Rating: {rating}\")\n",
    "    print(f\"Image URL: {image_url}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Failed to fetch the webpage. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Configure headers to mimic browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "def scrape_ecom(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract product details (ADJUST SELECTORS BASED ON TARGET SITE)\n",
    "        products = []\n",
    "        for item in soup.select('div.product-card'):  # Example selector\n",
    "            product = {\n",
    "                'name': item.select_one('h3.product-product').text.strip(),\n",
    "                'price': item.select_one('span.product-price').text.strip(),\n",
    "                'image': item.select_one('img.product-image')['src']\n",
    "            }\n",
    "            products.append(product)\n",
    "        return pd.DataFrame(products)\n",
    "    else:\n",
    "        print(\"Failed to retrieve page\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "df = scrape_ecom('https://www.myntra.com/men-tshirts')\n",
    "df.to_csv('products.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.myntra.com/men-tshirts?p=\"\n",
    "for page in range(1, 5):  # Scrape first 4 pages\n",
    "    scrape_ecom(f\"{base_url}{page}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(2)  # Add delay between requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "def scrape_ecom(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        products = []\n",
    "        for item in soup.select('div.product-productMetaInfo'):  # Example selector\n",
    "            product = {\n",
    "                'name': item.select_one('h3.product-product').text.strip(),\n",
    "                'price': item.select_one('span.product-discountedPrice').text.strip(),\n",
    "                'image': item.select_one('img.product-image')['src']\n",
    "            }\n",
    "            products.append(product)\n",
    "        \n",
    "        # Save and view scraped items\n",
    "        df = pd.DataFrame(products)\n",
    "        df.to_csv('scraped_products.csv', index=False)\n",
    "        print(df.head())  # View first few rows\n",
    "        \n",
    "    else:\n",
    "        print(\"Failed to retrieve page\")\n",
    "\n",
    "scrape_ecom('https://www.myntra.com/men-clothing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data scraped.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define headers to mimic a browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "def scrape_myntra(url):\n",
    "    # Send HTTP request to fetch page content\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract product details\n",
    "        products = []\n",
    "        for item in soup.select('li.product-base'):  # Adjust selector based on inspection\n",
    "            try:\n",
    "                product = {\n",
    "                    'brand': item.select_one('h3.product-brand').text.strip(),\n",
    "                    'name': item.select_one('h4.product-product').text.strip(),\n",
    "                    'price': item.select_one('span.product-discountedPrice').text.strip(),\n",
    "                    'original_price': item.select_one('span.product-strike').text.strip() if item.select_one('span.product-strike') else None,\n",
    "                    'discount': item.select_one('span.product-discountPercentage').text.strip() if item.select_one('span.product-discountPercentage') else None,\n",
    "                    'image_url': item.select_one('img.img-responsive')['src'] if item.select_one('img.img-responsive') else None,\n",
    "                }\n",
    "                products.append(product)\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping product: {e}\")\n",
    "        \n",
    "        return pd.DataFrame(products)\n",
    "    else:\n",
    "        print(f\"Failed to fetch page content: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# URL of Myntra's men's clothing page\n",
    "url = \"https://www.myntra.com/men-clothing\"\n",
    "\n",
    "# Scrape data and save it to a CSV file\n",
    "df = scrape_myntra(url)\n",
    "if df is not None and not df.empty:\n",
    "    df.to_csv(\"myntra_men_clothing.csv\", index=False)\n",
    "    print(\"Scraped data saved to myntra_men_clothing.csv\")\n",
    "else:\n",
    "    print(\"No data scraped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/25483098/2024/12/14/b40ee687-855a-4a11-8b99-8ed480d1b9fa1734169559541-HIGHLANDER-Men-Cargo-Trouser-4911734169558855-1.jpg\n",
      "{'brand': 'HIGHLANDER', 'name': 'Men Mid-Rise Cotton Cargos', 'price': 'Rs. 589', 'original_price': 'Rs. 589', 'image_url': 'https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/25483098/2024/12/14/b40ee687-855a-4a11-8b99-8ed480d1b9fa1734169559541-HIGHLANDER-Men-Cargo-Trouser-4911734169558855-1.jpg'}\n",
      "https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/24546994/2023/8/18/eac84911-3f92-421d-ae18-24525e90b73c1692359658660PrintedBandhgala2PcsSuitInNavyEdward1.jpg\n",
      "{'brand': 'Blackberrys', 'name': 'Woven Design Two-Piece Suit', 'price': 'Rs. 8816', 'original_price': 'Rs. 8816', 'image_url': 'https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/24546994/2023/8/18/eac84911-3f92-421d-ae18-24525e90b73c1692359658660PrintedBandhgala2PcsSuitInNavyEdward1.jpg'}\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/2025/MARCH/11/X0KRHZ7I_e12876f3fc1a4472aad735eea49d94a4.jpg\n",
      "{'brand': 'ONEWAY', 'name': 'Unisex Solid Cotton T-shirt', 'price': 'Rs. 559', 'original_price': 'Rs. 559', 'image_url': 'https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/2025/MARCH/11/X0KRHZ7I_e12876f3fc1a4472aad735eea49d94a4.jpg'}\n",
      "https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/29808850/2024/5/27/71294aea-e9d0-4188-b27b-49b4298dfe4e1716810154350CampusSutraMenComfortPleatedTrousers1.jpg\n",
      "{'brand': 'Campus Sutra', 'name': 'Men Comfort Pleated Trouser', 'price': 'Rs. 699', 'original_price': 'Rs. 699', 'image_url': 'https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/29808850/2024/5/27/71294aea-e9d0-4188-b27b-49b4298dfe4e1716810154350CampusSutraMenComfortPleatedTrousers1.jpg'}\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/31722588/2025/3/6/9e981de2-2083-4eb7-b816-c0bf281cefc51741264638987-Roadster-Men-Jeans-4821741264638151-1.jpg\n",
      "{'brand': 'Roadster', 'name': 'Men Light Fade Skater Jeans', 'price': 'Rs. 1007', 'original_price': 'Rs. 1007', 'image_url': 'https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/31722588/2025/3/6/9e981de2-2083-4eb7-b816-c0bf281cefc51741264638987-Roadster-Men-Jeans-4821741264638151-1.jpg'}\n",
      "https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/29808898/2024/5/28/fa996ea7-a065-45a8-b466-d79f5498d6cd1716896140127CampusSutraMenComfortTrousers2.jpg\n",
      "{'brand': 'Campus Sutra', 'name': 'Men Mid-Rise Plain Trousers', 'price': 'Rs. 799', 'original_price': 'Rs. 799', 'image_url': 'https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/29808898/2024/5/28/fa996ea7-a065-45a8-b466-d79f5498d6cd1716896140127CampusSutraMenComfortTrousers2.jpg'}\n",
      "https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/2025/MARCH/3/Up1iHuJz_b4d62fa014bb4cef9e243f8b501f0857.jpg\n",
      "{'brand': 'Styli', 'name': 'Men Fit Shirt & Shorts Co-ords', 'price': 'Rs. 1999', 'original_price': 'Rs. 1999', 'image_url': 'https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/2025/MARCH/3/Up1iHuJz_b4d62fa014bb4cef9e243f8b501f0857.jpg'}\n",
      "https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/31598736/2025/2/20/244284a8-fead-4cb8-a056-5957c51786271740034342802-Mens-Causal-Tshirt-6541740034342352-1.jpg\n",
      "{'brand': 'Flying Machine', 'name': 'Pure Cotton Relaxed T-shirt', 'price': 'Rs. 649', 'original_price': 'Rs. 649', 'image_url': 'https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/31598736/2025/2/20/244284a8-fead-4cb8-a056-5957c51786271740034342802-Mens-Causal-Tshirt-6541740034342352-1.jpg'}\n",
      "https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/29920019/2025/2/4/1d4c7a79-281d-4ba8-90a7-44944b6bcefa1738665525529-WROGN-Striped-Polo-Collar-Drop-Shoulder-Sleeves-Oversized-Pu-1.jpg\n",
      "{'brand': 'WROGN', 'name': 'Oversized Pure Cotton T-shirt', 'price': 'Rs. 989', 'original_price': 'Rs. 989', 'image_url': 'https://assets.myntassets.com/dpr_2,q_60,w_210,c_limit,fl_progressive/assets/images/29920019/2025/2/4/1d4c7a79-281d-4ba8-90a7-44944b6bcefa1738665525529-WROGN-Striped-Polo-Collar-Drop-Shoulder-Sleeves-Oversized-Pu-1.jpg'}\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "Error scraping product: 'NoneType' object is not subscriptable\n",
      "            brand                            name     price original_price  \\\n",
      "0      HIGHLANDER      Men Mid-Rise Cotton Cargos   Rs. 589        Rs. 589   \n",
      "1     Blackberrys     Woven Design Two-Piece Suit  Rs. 8816       Rs. 8816   \n",
      "2          ONEWAY     Unisex Solid Cotton T-shirt   Rs. 559        Rs. 559   \n",
      "3    Campus Sutra     Men Comfort Pleated Trouser   Rs. 699        Rs. 699   \n",
      "4        Roadster     Men Light Fade Skater Jeans  Rs. 1007       Rs. 1007   \n",
      "5    Campus Sutra     Men Mid-Rise Plain Trousers   Rs. 799        Rs. 799   \n",
      "6           Styli  Men Fit Shirt & Shorts Co-ords  Rs. 1999       Rs. 1999   \n",
      "7  Flying Machine     Pure Cotton Relaxed T-shirt   Rs. 649        Rs. 649   \n",
      "8           WROGN   Oversized Pure Cotton T-shirt   Rs. 989        Rs. 989   \n",
      "\n",
      "                                           image_url  \n",
      "0  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n",
      "1  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n",
      "2  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n",
      "3  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n",
      "4  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n",
      "5  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n",
      "6  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n",
      "7  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n",
      "8  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Configure Selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in background\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "\n",
    "def scrape_myntra(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Initial load\n",
    "    \n",
    "    # Scroll to load all products (adjust scroll count)\n",
    "    for _ in range(3):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Wait for product elements to load\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    products = []\n",
    "    \n",
    "    # for item in soup.select('li.product-base'):\n",
    "    #     print(item.select_one('h3.product-brand').text)  # Check if brand exists\n",
    "    #     print(item.select_one('h4.product-product'))  # Check if name exists\n",
    "\n",
    "    # Extract product details\n",
    "    for item in soup.select('li.product-base'):\n",
    "        \n",
    "        soup.prettify()  # View the parsed HTML\n",
    "        # print(soup.select('li.product-base'))  # Check if product elements are being selected\n",
    "# Adjust selector\n",
    "        try:\n",
    "            brand_element = item.select_one('h3.product-brand').text\n",
    "            # print(brand_element.text)\n",
    "            name_element = item.select_one('h4.product-product').text\n",
    "            price_element = item.select_one('span.product-discountedPrice').text\n",
    "            ori_price_element = item.select_one('span.product-discountedPrice').text\n",
    "            image = item.select_one('img.img-responsive')['src']\n",
    "            print(image)\n",
    "            # print(price_element)\n",
    "            \n",
    "            product = {\n",
    "                'brand': brand_element if brand_element else \"Brand not found\",\n",
    "                'name': name_element if name_element else \"Name not found\",\n",
    "                'price': price_element if price_element else \"Price not found\",\n",
    "                'original_price': ori_price_element if ori_price_element else \"ori_price_element not found\",\n",
    "                'image_url': image if image else \"Image not found\",\n",
    "            }\n",
    "            print(product)\n",
    "            products.append(product)\n",
    "            # product = {\n",
    "            #     'brand': item.select_one('h3.product-brand').text,\n",
    "            #     'name': item.select_one('h4.product-product').text,\n",
    "            #     'price': item.select_one('span.product-discountedPrice').text,\n",
    "            #     # 'original_price': item.select_one('span.product-strike').text if item.select_one('span.product-strike') else None,\n",
    "            #     # 'image': item.select_one('img.img-responsive')['src'] if item.select_one('img.img-responsive') else None,\n",
    "            # }\n",
    "            # products.append(product)\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping product: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(products)\n",
    "\n",
    "# Example usage\n",
    "df = scrape_myntra(\"https://www.myntra.com/men-clothing\")\n",
    "print(df)\n",
    "# df.to_csv(\"myntra_products.csv\", index=False)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "brand",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6ccd2aea-970d-4f5e-93e6-8086714efa64",
       "rows": [
        [
         "0",
         "HIGHLANDER",
         "Men Mid-Rise Cotton Cargos"
        ],
        [
         "1",
         "Campus Sutra",
         "Men Solid Cotton Casual Shirt"
        ],
        [
         "2",
         "The Souled Store",
         "Men Printed Boxers"
        ],
        [
         "3",
         "ONEWAY",
         "Unisex Solid Cotton T-shirt"
        ],
        [
         "4",
         "Blackberrys",
         "Woven Design Two-Piece Suit"
        ],
        [
         "5",
         "Ramraj",
         "Men Dhotis"
        ],
        [
         "6",
         "Roadster",
         "Men Light Fade Skater Jeans"
        ],
        [
         "7",
         "Campus Sutra",
         "Men Comfort Pleated Trouser"
        ],
        [
         "8",
         "Styli",
         "Men Fit Shirt & Shorts Co-ords"
        ],
        [
         "9",
         "Flying Machine",
         "Pure Cotton Relaxed T-shirt"
        ],
        [
         "10",
         "Campus Sutra",
         "Men Mid-Rise Plain Trousers"
        ],
        [
         "11",
         "U.S. Polo Assn.",
         "Men Relaxed-Fit Shorts"
        ],
        [
         "12",
         "Mast & Harbour",
         "Men Slim Fit Casual Shirt"
        ],
        [
         "13",
         "WROGN",
         "Oversized Pure Cotton T-shirt"
        ],
        [
         "14",
         "Roadster",
         "Chambray Casual Shirt"
        ],
        [
         "15",
         "Sangria",
         "Men Solid Mid Rise Dhoti"
        ],
        [
         "16",
         "DAMENSCH",
         "DEO-SOFT Deodorizing Trunks"
        ],
        [
         "17",
         "VASTRAMAY",
         "Embroidered Sherwani Set"
        ],
        [
         "18",
         "Jompers",
         "Embroidered Kurta with Pyjamas"
        ],
        [
         "19",
         "Celio",
         "Men Cargos Trousers"
        ],
        [
         "20",
         "Vastraa Fusion",
         "Pure Wool Nehru Jacket"
        ],
        [
         "21",
         "DAMENSCH",
         "DEO-SOFT Deodorizing Trunks"
        ],
        [
         "22",
         "Blackberrys",
         "Slim-Fit Three-Piece Suit"
        ],
        [
         "23",
         "Jompers",
         "Embroidered Pure Cotton Kurta"
        ],
        [
         "24",
         "U.S. Polo Assn.",
         "Basic Anti Bacterial Briefs"
        ],
        [
         "25",
         "Blackberrys",
         "Men Slim-Fit 4 Pcs Suit"
        ],
        [
         "26",
         "Jockey",
         "Men Printed Cotton Trunk"
        ],
        [
         "27",
         "Mast & Harbour",
         "Striped Shorts Set"
        ],
        [
         "28",
         "Campus Sutra",
         "Men Mid Rise Cotton Trousers"
        ],
        [
         "29",
         "VASTRAMAY",
         "Embroidered Sherwani Set"
        ],
        [
         "30",
         "HRX by Hrithik Roshan",
         "Men Parachute Track Pants"
        ],
        [
         "31",
         "HIGHLANDER",
         "Slim Fit Cotton Casual Shirt"
        ],
        [
         "32",
         "John Players",
         "Men Lounge Shorts"
        ],
        [
         "33",
         "MANQ",
         "Men Slim Fit Formal Blazer"
        ],
        [
         "34",
         "Levis",
         "Men Solid Trunks"
        ],
        [
         "35",
         "Beyoung",
         "Loose-Fit Cotton Lounge Pants"
        ],
        [
         "36",
         "Pepe Jeans",
         "Pack Of 2 Pure Cotton Boxers"
        ],
        [
         "37",
         "Campus Sutra",
         "Men Mid Rise Cotton Trousers"
        ],
        [
         "38",
         "VASTRAMAY",
         "Men Indo-Western Sherwani Set"
        ],
        [
         "39",
         "U.S. Polo Assn.",
         "Cotton OELP6 Lounge Pants"
        ],
        [
         "40",
         "Campus Sutra",
         "Men Trousers"
        ],
        [
         "41",
         "V-Mart",
         "Woven Designed Nehru Jacket"
        ],
        [
         "42",
         "Jompers",
         "Embroidered Cotton Kurta Set"
        ],
        [
         "43",
         "Blackberrys",
         "Men Three-Piece Formal Suit"
        ],
        [
         "44",
         "ISUEL FAB",
         "Men Striped Night suit"
        ],
        [
         "45",
         "max",
         "Men Solid Lounge Shorts"
        ],
        [
         "46",
         "HIGHLANDER",
         "Men Mid-Rise Joggers"
        ],
        [
         "47",
         "Roadster",
         "Relaxed-Fit Regular Trousers"
        ],
        [
         "48",
         "Ramraj",
         "Men Solid Adjustable Dhoti"
        ],
        [
         "49",
         "HERE&NOW",
         "Men Short Kurta"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 50
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Men Mid-Rise Cotton Cargos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Campus Sutra</td>\n",
       "      <td>Men Solid Cotton Casual Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Souled Store</td>\n",
       "      <td>Men Printed Boxers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ONEWAY</td>\n",
       "      <td>Unisex Solid Cotton T-shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blackberrys</td>\n",
       "      <td>Woven Design Two-Piece Suit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ramraj</td>\n",
       "      <td>Men Dhotis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Men Light Fade Skater Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Campus Sutra</td>\n",
       "      <td>Men Comfort Pleated Trouser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Styli</td>\n",
       "      <td>Men Fit Shirt &amp; Shorts Co-ords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Flying Machine</td>\n",
       "      <td>Pure Cotton Relaxed T-shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Campus Sutra</td>\n",
       "      <td>Men Mid-Rise Plain Trousers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>U.S. Polo Assn.</td>\n",
       "      <td>Men Relaxed-Fit Shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mast &amp; Harbour</td>\n",
       "      <td>Men Slim Fit Casual Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WROGN</td>\n",
       "      <td>Oversized Pure Cotton T-shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Chambray Casual Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sangria</td>\n",
       "      <td>Men Solid Mid Rise Dhoti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DAMENSCH</td>\n",
       "      <td>DEO-SOFT Deodorizing Trunks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VASTRAMAY</td>\n",
       "      <td>Embroidered Sherwani Set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Jompers</td>\n",
       "      <td>Embroidered Kurta with Pyjamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Celio</td>\n",
       "      <td>Men Cargos Trousers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Vastraa Fusion</td>\n",
       "      <td>Pure Wool Nehru Jacket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DAMENSCH</td>\n",
       "      <td>DEO-SOFT Deodorizing Trunks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Blackberrys</td>\n",
       "      <td>Slim-Fit Three-Piece Suit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Jompers</td>\n",
       "      <td>Embroidered Pure Cotton Kurta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>U.S. Polo Assn.</td>\n",
       "      <td>Basic Anti Bacterial Briefs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Blackberrys</td>\n",
       "      <td>Men Slim-Fit 4 Pcs Suit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Jockey</td>\n",
       "      <td>Men Printed Cotton Trunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mast &amp; Harbour</td>\n",
       "      <td>Striped Shorts Set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Campus Sutra</td>\n",
       "      <td>Men Mid Rise Cotton Trousers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>VASTRAMAY</td>\n",
       "      <td>Embroidered Sherwani Set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Men Parachute Track Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Slim Fit Cotton Casual Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>John Players</td>\n",
       "      <td>Men Lounge Shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MANQ</td>\n",
       "      <td>Men Slim Fit Formal Blazer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Levis</td>\n",
       "      <td>Men Solid Trunks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Beyoung</td>\n",
       "      <td>Loose-Fit Cotton Lounge Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Pepe Jeans</td>\n",
       "      <td>Pack Of 2 Pure Cotton Boxers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Campus Sutra</td>\n",
       "      <td>Men Mid Rise Cotton Trousers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>VASTRAMAY</td>\n",
       "      <td>Men Indo-Western Sherwani Set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>U.S. Polo Assn.</td>\n",
       "      <td>Cotton OELP6 Lounge Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Campus Sutra</td>\n",
       "      <td>Men Trousers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>V-Mart</td>\n",
       "      <td>Woven Designed Nehru Jacket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Jompers</td>\n",
       "      <td>Embroidered Cotton Kurta Set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Blackberrys</td>\n",
       "      <td>Men Three-Piece Formal Suit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ISUEL FAB</td>\n",
       "      <td>Men Striped Night suit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>max</td>\n",
       "      <td>Men Solid Lounge Shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Men Mid-Rise Joggers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Relaxed-Fit Regular Trousers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Ramraj</td>\n",
       "      <td>Men Solid Adjustable Dhoti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>HERE&amp;NOW</td>\n",
       "      <td>Men Short Kurta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    brand                            name\n",
       "0              HIGHLANDER      Men Mid-Rise Cotton Cargos\n",
       "1            Campus Sutra   Men Solid Cotton Casual Shirt\n",
       "2        The Souled Store              Men Printed Boxers\n",
       "3                  ONEWAY     Unisex Solid Cotton T-shirt\n",
       "4             Blackberrys     Woven Design Two-Piece Suit\n",
       "5                  Ramraj                      Men Dhotis\n",
       "6                Roadster     Men Light Fade Skater Jeans\n",
       "7            Campus Sutra     Men Comfort Pleated Trouser\n",
       "8                   Styli  Men Fit Shirt & Shorts Co-ords\n",
       "9          Flying Machine     Pure Cotton Relaxed T-shirt\n",
       "10           Campus Sutra     Men Mid-Rise Plain Trousers\n",
       "11        U.S. Polo Assn.          Men Relaxed-Fit Shorts\n",
       "12         Mast & Harbour       Men Slim Fit Casual Shirt\n",
       "13                  WROGN   Oversized Pure Cotton T-shirt\n",
       "14               Roadster           Chambray Casual Shirt\n",
       "15                Sangria        Men Solid Mid Rise Dhoti\n",
       "16               DAMENSCH     DEO-SOFT Deodorizing Trunks\n",
       "17              VASTRAMAY        Embroidered Sherwani Set\n",
       "18                Jompers  Embroidered Kurta with Pyjamas\n",
       "19                  Celio             Men Cargos Trousers\n",
       "20         Vastraa Fusion          Pure Wool Nehru Jacket\n",
       "21               DAMENSCH     DEO-SOFT Deodorizing Trunks\n",
       "22            Blackberrys       Slim-Fit Three-Piece Suit\n",
       "23                Jompers   Embroidered Pure Cotton Kurta\n",
       "24        U.S. Polo Assn.     Basic Anti Bacterial Briefs\n",
       "25            Blackberrys         Men Slim-Fit 4 Pcs Suit\n",
       "26                 Jockey        Men Printed Cotton Trunk\n",
       "27         Mast & Harbour              Striped Shorts Set\n",
       "28           Campus Sutra    Men Mid Rise Cotton Trousers\n",
       "29              VASTRAMAY        Embroidered Sherwani Set\n",
       "30  HRX by Hrithik Roshan       Men Parachute Track Pants\n",
       "31             HIGHLANDER    Slim Fit Cotton Casual Shirt\n",
       "32           John Players               Men Lounge Shorts\n",
       "33                   MANQ      Men Slim Fit Formal Blazer\n",
       "34                  Levis                Men Solid Trunks\n",
       "35                Beyoung   Loose-Fit Cotton Lounge Pants\n",
       "36             Pepe Jeans    Pack Of 2 Pure Cotton Boxers\n",
       "37           Campus Sutra    Men Mid Rise Cotton Trousers\n",
       "38              VASTRAMAY   Men Indo-Western Sherwani Set\n",
       "39        U.S. Polo Assn.       Cotton OELP6 Lounge Pants\n",
       "40           Campus Sutra                    Men Trousers\n",
       "41                 V-Mart     Woven Designed Nehru Jacket\n",
       "42                Jompers    Embroidered Cotton Kurta Set\n",
       "43            Blackberrys     Men Three-Piece Formal Suit\n",
       "44              ISUEL FAB          Men Striped Night suit\n",
       "45                    max         Men Solid Lounge Shorts\n",
       "46             HIGHLANDER            Men Mid-Rise Joggers\n",
       "47               Roadster    Relaxed-Fit Regular Trousers\n",
       "48                 Ramraj      Men Solid Adjustable Dhoti\n",
       "49               HERE&NOW                 Men Short Kurta"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "          brand                         name     price  \\\n",
      "0    HIGHLANDER   Men Mid-Rise Cotton Cargos   Rs. 589   \n",
      "1   Blackberrys  Woven Design Two-Piece Suit  Rs. 8816   \n",
      "2        ONEWAY  Unisex Solid Cotton T-shirt   Rs. 559   \n",
      "3  Campus Sutra  Men Comfort Pleated Trouser   Rs. 699   \n",
      "4      Roadster  Men Light Fade Skater Jeans  Rs. 1007   \n",
      "\n",
      "                                           image_url  \n",
      "0  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n",
      "1  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n",
      "2  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n",
      "3  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n",
      "4  https://assets.myntassets.com/dpr_2,q_60,w_210...  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Configure Selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in background\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "\n",
    "def scrape_myntra(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Initial load\n",
    "    \n",
    "    # Scroll multiple times to load all products (adjust scroll count)\n",
    "    for _ in range(10):  # Increase scroll count for lazy loading\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Extract page source after scrolling\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    products = []\n",
    "    \n",
    "    # Extract product details\n",
    "    for item in soup.select('li.product-base'):\n",
    "        try:\n",
    "            brand_element = item.select_one('h3.product-brand').text.strip()\n",
    "            name_element = item.select_one('h4.product-product').text.strip()\n",
    "            price_element = item.select_one('span.product-discountedPrice').text.strip()\n",
    "            \n",
    "            # Handle lazy-loaded images with fallback for 'data-src'\n",
    "            image_element = item.select_one('img.img-responsive')\n",
    "            image_url = image_element['data-src'] if 'data-src' in image_element.attrs else image_element['src']\n",
    "            \n",
    "            product = {\n",
    "                'brand': brand_element if brand_element else \"Brand not found\",\n",
    "                'name': name_element if name_element else \"Name not found\",\n",
    "                'price': price_element if price_element else \"Price not found\",\n",
    "                'image_url': image_url if image_url else \"Image not found\",\n",
    "            }\n",
    "            products.append(product)\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping product: {str(e)}\")\n",
    "    \n",
    "    return pd.DataFrame(products)\n",
    "\n",
    "# Example usage\n",
    "df = scrape_myntra(\"https://www.myntra.com/men-clothing\")\n",
    "print(df.head())\n",
    "df.to_csv(\"myntra_products.csv\", index=False)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n",
      "Error scraping product: 'NoneType' object has no attribute 'text'\n",
      "Error scraping product: 'NoneType' object has no attribute 'attrs'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m all_products \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# Scrape first 5 pages\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     df_page \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_myntra\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     all_products\u001b[38;5;241m.\u001b[39mappend(df_page)\n\u001b[0;32m     58\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_products)\n",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m, in \u001b[0;36mscrape_myntra\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m     24\u001b[0m     driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow.scrollTo(0, document.body.scrollHeight);\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m products \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "\n",
    "def scrape_myntra(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "  \n",
    "    for _ in range(200):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    products = []\n",
    " \n",
    "    for item in soup.select('li.product-base'):\n",
    "        try:\n",
    "            brand_element = item.select_one('h3.product-brand').text\n",
    "            name_element = item.select_one('h4.product-product').text\n",
    "            price_element = item.select_one('span.product-discountedPrice').text\n",
    "            \n",
    "            image_element = item.select_one('img.img-responsive')\n",
    "            image_url = image_element['data-src'] if 'data-src' in image_element.attrs else image_element['src']\n",
    "            \n",
    "            product = {\n",
    "                'brand': brand_element,\n",
    "                'name': name_element,\n",
    "                'price': price_element,\n",
    "                'image_url': image_url,\n",
    "            }\n",
    "            products.append(product)\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping product: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(products)\n",
    "\n",
    "base_url = \"https://www.myntra.com/men-clothing?p=\"\n",
    "all_products = []\n",
    "\n",
    "for page in range(1, 50):  # Scrape first 5 pages\n",
    "    df_page = scrape_myntra(f\"{base_url}{page}\")\n",
    "    all_products.append(df_page)\n",
    "\n",
    "final_df = pd.concat(all_products)\n",
    "final_df.to_csv(\"myntra_all_products.csv\", index=False)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WROGN\n",
      "<h4 class=\"product-product\">Oversized Pure Cotton T-shirt</h4>\n",
      "HIGHLANDER\n",
      "<h4 class=\"product-product\">Men Self Design Cotton Shirt</h4>\n",
      "The Souled Store\n",
      "<h4 class=\"product-product\">Men Printed Boxers</h4>\n",
      "ONEWAY\n",
      "<h4 class=\"product-product\">Unisex Solid Cotton T-shirt</h4>\n",
      "DAMENSCH\n",
      "<h4 class=\"product-product\">DEO-SOFT Deodorizing Trunks</h4>\n",
      "Ramraj\n",
      "<h4 class=\"product-product\">Men Dhotis</h4>\n",
      "Roadster\n",
      "<h4 class=\"product-product\">Men Light Fade Skater Jeans</h4>\n",
      "Dennis Lingo\n",
      "<h4 class=\"product-product\">Men Polo Collar T-shirt</h4>\n",
      "Styli\n",
      "<h4 class=\"product-product\">Men Fit Shirt &amp; Shorts Co-ords</h4>\n",
      "Flying Machine\n",
      "<h4 class=\"product-product\">Pure Cotton Relaxed T-shirt</h4>\n",
      "Levis\n",
      "<h4 class=\"product-product\">Men Solid Trunks</h4>\n",
      "U.S. Polo Assn.\n",
      "<h4 class=\"product-product\">Men Relaxed-Fit Shorts</h4>\n",
      "Mast & Harbour\n",
      "<h4 class=\"product-product\">Men Slim Fit Casual Shirt</h4>\n",
      "HIGHLANDER\n",
      "<h4 class=\"product-product\">Opaque Casual Shirt</h4>\n",
      "Roadster\n",
      "<h4 class=\"product-product\">Chambray Casual Shirt</h4>\n",
      "Sangria\n",
      "<h4 class=\"product-product\">Men Solid Mid Rise Dhoti</h4>\n",
      "Dennis Lingo\n",
      "<h4 class=\"product-product\">Men Polo Collar T-shirt</h4>\n",
      "VASTRAMAY\n",
      "<h4 class=\"product-product\">Embroidered Sherwani Set</h4>\n",
      "Jompers\n",
      "<h4 class=\"product-product\">Embroidered Kurta with Pyjamas</h4>\n",
      "HERE&NOW\n",
      "<h4 class=\"product-product\">Men Short Kurta</h4>\n",
      "Vastraa Fusion\n",
      "<h4 class=\"product-product\">Pure Wool Nehru Jacket</h4>\n",
      "DAMENSCH\n",
      "<h4 class=\"product-product\">DEO-SOFT Deodorizing Trunks</h4>\n",
      "Dennis Lingo\n",
      "<h4 class=\"product-product\">Men Polo Collar T-shirt</h4>\n",
      "Jompers\n",
      "<h4 class=\"product-product\">Embroidered Pure Cotton Kurta</h4>\n",
      "U.S. Polo Assn.\n",
      "<h4 class=\"product-product\">Basic Anti Bacterial Briefs</h4>\n",
      "Manyavar\n",
      "<h4 class=\"product-product\">Men Kurta</h4>\n",
      "Jockey\n",
      "<h4 class=\"product-product\">Men Printed Cotton Trunk</h4>\n",
      "Mast & Harbour\n",
      "<h4 class=\"product-product\">Striped Shorts Set</h4>\n",
      "HIGHLANDER\n",
      "<h4 class=\"product-product\">Men Checked Cotton Shirt</h4>\n",
      "VASTRAMAY\n",
      "<h4 class=\"product-product\">Embroidered Sherwani Set</h4>\n",
      "HRX by Hrithik Roshan\n",
      "<h4 class=\"product-product\">Men Parachute Track Pants</h4>\n",
      "Raymond\n",
      "<h4 class=\"product-product\">Men Slim Fit Formal Trousers</h4>\n",
      "John Players\n",
      "<h4 class=\"product-product\">Men Lounge Shorts</h4>\n",
      "MANQ\n",
      "<h4 class=\"product-product\">Men Slim Fit Formal Blazer</h4>\n",
      "DAMENSCH\n",
      "<h4 class=\"product-product\">Pack Of 3 Deo-Soft Trunk</h4>\n",
      "Beyoung\n",
      "<h4 class=\"product-product\">Loose-Fit Cotton Lounge Pants</h4>\n",
      "Pepe Jeans\n",
      "<h4 class=\"product-product\">Pack Of 2 Pure Cotton Boxers</h4>\n",
      "Manyavar\n",
      "<h4 class=\"product-product\">Embroidered Kurta with Pyjamas</h4>\n",
      "VASTRAMAY\n",
      "<h4 class=\"product-product\">Men Indo-Western Sherwani Set</h4>\n",
      "U.S. Polo Assn.\n",
      "<h4 class=\"product-product\">Cotton OELP6 Lounge Pants</h4>\n",
      "Aeropostale\n",
      "<h4 class=\"product-product\">Relaxed Fit Cotton T-shirt</h4>\n",
      "V-Mart\n",
      "<h4 class=\"product-product\">Woven Designed Nehru Jacket</h4>\n",
      "Jompers\n",
      "<h4 class=\"product-product\">Embroidered Cotton Kurta Set</h4>\n",
      "WROGN\n",
      "<h4 class=\"product-product\">Men Slim Fit Casual Shirt</h4>\n",
      "ISUEL FAB\n",
      "<h4 class=\"product-product\">Men Striped Night suit</h4>\n",
      "max\n",
      "<h4 class=\"product-product\">Men Solid Lounge Shorts</h4>\n",
      "Levis\n",
      "<h4 class=\"product-product\">Men Pack of 2 Cotton Trunk</h4>\n",
      "Roadster\n",
      "<h4 class=\"product-product\">Relaxed-Fit Regular Trousers</h4>\n",
      "Ramraj\n",
      "<h4 class=\"product-product\">Men Solid Adjustable Dhoti</h4>\n",
      "HERE&NOW\n",
      "<h4 class=\"product-product\">Men Liva Kurta</h4>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 59\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Extract product details\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#     for item in soup.select('li.product-base'):\u001b[39;00m\n\u001b[0;32m     38\u001b[0m         \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     58\u001b[0m df \u001b[38;5;241m=\u001b[39m scrape_myntra(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.myntra.com/men-clothing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmyntra_products.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     60\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Configure Selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in background\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "\n",
    "def scrape_myntra(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Initial load\n",
    "    \n",
    "    # Scroll to load all products (adjust scroll count)\n",
    "    for _ in range(3):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Wait for product elements to load\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    # products = []\n",
    "    \n",
    "    for item in soup.select('li.product-base'):\n",
    "        print(item.select_one('h3.product-brand').text)  # Check if brand exists\n",
    "        print(item.select_one('h4.product-product'))  # Check if name exists\n",
    "\n",
    "    # Extract product details\n",
    "#     for item in soup.select('li.product-base'):\n",
    "        \n",
    "#         print(soup.prettify())  # View the parsed HTML\n",
    "#         print(soup.select('li.product-base'))  # Check if product elements are being selected\n",
    "# # Adjust selector\n",
    "#         try:\n",
    "#             product = {\n",
    "#                 'brand': item.select_one('h3.product-brand').text.strip(),\n",
    "#                 'name': item.select_one('h4.product-product').text.strip(),\n",
    "#                 'price': item.select_one('span.product-discountedPrice').text.strip(),\n",
    "#                 'original_price': item.select_one('span.product-strike').text.strip() if item.select_one('span.product-strike') else None,\n",
    "#                 'image': item.select_one('img.img-responsive')['src'] if item.select_one('img.img-responsive') else None,\n",
    "#             }\n",
    "#             products.append(product)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error scraping product: {str(e)}\")\n",
    "#             continue\n",
    "    \n",
    "#     return pd.DataFrame(products)\n",
    "\n",
    "# Example usage\n",
    "df = scrape_myntra(\"https://www.myntra.com/men-clothing\")\n",
    "df.to_csv(\"myntra_products.csv\", index=False)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data scraped.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define headers to mimic a browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "def scrape_myntra(url):\n",
    "    # Send HTTP request to fetch page content\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract product details\n",
    "        products = []\n",
    "        for item in soup.select('li.product-base'):  # Loop through all product elements\n",
    "            try:\n",
    "                brand_element = item.select_one('h3.product-brand')\n",
    "                name_element = item.select_one('h4.product-product')\n",
    "                \n",
    "                product = {\n",
    "                    'brand': brand_element.text.strip() if brand_element else \"Brand not found\",\n",
    "                    'name': name_element.text.strip() if name_element else \"Name not found\",\n",
    "                }\n",
    "                products.append(product)\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping product: {e}\")\n",
    "        \n",
    "        return pd.DataFrame(products)\n",
    "    else:\n",
    "        print(f\"Failed to fetch page content: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# URL of Myntra's men's clothing page\n",
    "url = \"https://www.myntra.com/men-clothing\"\n",
    "\n",
    "# Scrape data and save it to a CSV file\n",
    "df = scrape_myntra(url)\n",
    "if df is not None and not df.empty:\n",
    "    print(df.head())  # Preview first few rows\n",
    "    df.to_csv(\"myntra_men_clothing.csv\", index=False)\n",
    "    print(\"Scraped data saved to myntra_men_clothing.csv\")\n",
    "else:\n",
    "    print(\"No data scraped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install selenium webdriver-manager pandas\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Configure Selenium\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\") # Run in background\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "service=Service(ChromeDriverManager().install()),\n",
    "options=options\n",
    ")\n",
    "\n",
    "def scrape_myntra(url):\n",
    "driver.get(url)\n",
    "time.sleep(3) # Initial load\n",
    "\n",
    "    # Scroll to load all products (adjust scroll count)\n",
    "    for _ in range(3):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "    # Wait for product elements to load\n",
    "    WebDriverWait(driver, 15).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"product-base\"))\n",
    "    )\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    products = []\n",
    "\n",
    "    # Extract product details\n",
    "    for item in soup.select('li.product-base'):\n",
    "        try:\n",
    "            product = {\n",
    "                'brand': item.select_one('h3.product-brand').text.strip(),\n",
    "                'name': item.select_one('h4.product-product').text.strip(),\n",
    "                'price': item.select_one('span.product-discountedPrice').text.strip(),\n",
    "                'original_price': item.select_one('span.product-strike').text.strip() if item.select_one('span.product-strike') else None,\n",
    "                'image': item.select_one('img.img-responsive')['src'],\n",
    "                'rating': item.select_one('div.product-ratingsContainer > span:first-child').text.strip() if item.select_one('div.product-ratingsContainer') else None\n",
    "            }\n",
    "            products.append(product)\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping product: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(products)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "df = scrape_myntra(\"https://www.myntra.com/men-clothing\")\n",
    "df.to_csv(\"myntra_products.csv\", index=False)\n",
    "driver.quit()\n",
    "\n",
    "# pagination:\n",
    "\n",
    "base_url = \"https://www.myntra.com/men-clothing?p=\"\n",
    "all_products = []\n",
    "\n",
    "for page in range(1, 4): # Scrape first 3 pages\n",
    "print(f\"Scraping page {page}\")\n",
    "df = scrape_myntra(f\"{base_url}{page}\")\n",
    "all_products.append(df)\n",
    "time.sleep(5) # Avoid rate limiting\n",
    "\n",
    "final_df = pd.concat(all_products)\n",
    "final_df.to_csv(\"myntra_all_products.csv\", index=False)\n",
    "\n",
    "# proxy rotation\n",
    "\n",
    "options.add_argument(\"--proxy-server=123.45.67.89:8080\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
